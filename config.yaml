seed: 1
epoch: 10
block_size: 5
block_decay: .5
preconditioner: None
optimizer: psgld2.pSGLD
accept_model: False
ekfac.EKFAC:
  eps: 1.e-3
  sua: False
  ra: True
  update_freq: 50
  alpha: .5
eksgld.EKSGLD:
  lr: 5.e-3
  train_size: 60000
  num_burn_in_steps: 600
  add_noise: True
  eps: 1.e-3   # Tikhonov regularization
  sua: False  # Applies SUA approximation.
  ra: True
  update_freq: 50
  alpha: .5   # Running average parameter (if == 1, no r. ave.).
  update_style: ksgld
ksgld.KSGLD:
  lr: 3.2e-2
  num_burn_in_steps: 600
  add_noise: True
  eps: 1.e-3   # Tikhonov regularization
  sua: True  # Applies SUA approximation.
  pi: False   # pi conrrection for Tikhonov regularization
  update_freq: 50
  alpha: 1.   # Running average parameter (if == 1, no r. ave.).
  constraint_norm: True  # Scale the gradients by the squared fisher norm.
kfac.KFAC:
  eps: 1.e-3   # Tikhonov regularization
  sua: True  # Applies SUA approximation.
  pi: False   # pi conrrection for Tikhonov regularization
  update_freq: 50
  alpha: 1.   # Running average parameter (if == 1, no r. ave.).
  constraint_norm: False  # Scale the gradients by the squared fisher norm.
optim.SGD:
  lr: 1.e-1
optim.RMSprop:
  lr: 5.e-4
  weight_decay: 1.e-2
pysgmcmc_sgld.SGLD:
  lr: 5.e-4 # for pSGLD
  precondition_decay_rate: .95 # Exponential decay rate of the rescaling of the preconditioner (RMSprop)
  num_burn_in_steps: 10
  diagonal_bias: 1.e-8
sgld.SGLD:
  lr: 0.0005005742963403476 # for vanilla SGLD
  # lr: 99.e-2 # for pSGLD
  precondition_decay_rate: .95 # Exponential decay rate of the rescaling of the preconditioner (RMSprop)
  num_burn_in_steps: 610
  diagonal_bias: 1.e-8
  vanilla: True
sgld2.SGLD:
  lr: 0.5
  num_burn_in_steps: 300
sgld3.SGLD:
  lr: .1
  train_size: 60000
  lr_decay: 2.e-2
  weight_decay: 0.
  num_burn_in_steps: 300
psgld.pSGLD:
  lr: 1.e-2
  diagonal_bias: 5.e-5
  num_pseudo_batches: 1
  precondition_decay_rate: .95
  num_burn_in_steps: 300
psgld2.pSGLD:
  lr: 1.e-3
  train_size: 60000
  alpha: .95
  eps: 5.e-5
  num_burn_in_steps: 300
  centered: False
  addnoise: True
psgld3.pSGLD:
  lr: 1.e-3
  train_size: 60000
  lr_decay: 0.
  weight_decay: 0.
  num_burn_in_steps: 300
  rmsprop_decay: .99
  eps: 1.e-5
asgld.ASGLD:
  lr: 2.e-1
  momentum: .9
  weight_decay: 5.e-4
  eps: 5.e-5
  noise: 2.e-2
dataset:
  train_batch: 200
  test_batch: 200
percentage_tosample: .1
step_samples: 10
step_save_state: 100